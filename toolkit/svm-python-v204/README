
svmstruct_mrf Specific Options:
         --m module_name   ->  the module name, which is 'svmstruct_mrf'
		 --lm learning_method -> the learning method (default : objassoc):
								objassoc : the parsimonious model 
								nonassoc : the non associative model
		 --omf object_map_file -> the location of the object mapping file to be used
		 --amf attribute_map_file -> the location of the attribute mapping file
		 --cm classify_method -> the classification method used (default is sum1.IP):
								 sum1 : linear programing using the sum = 1 constraint
								 sum1.IP : use MIP solver using the sum = 1 constraint
								 qbpo : use qbpo method
								 qbpo.sum1.IP : solve using the qbpo method first and initialize the MIP solver with its solution
		 --am attribute_method -> if multiple labeling method is to be used (default false):
								  true: multiple labels for a single instance are allowed
								  false: only one label is allowed
		 
								 
Training and Classification scripts:

 run_sequential.sh : runs the learner and classifier for all the folds sequentially and agregates the metrics over all folds.
 run_parallel.sh : runs all the folds parallely and agregates the metrics over all folds. 
 

Steps to run the training and classfication:
Step 1 : Create a directory inside svm-python-v204 and copy the following files into that directory.

Feature and Data Files: (The node and edge feature files can be either downloaded from the website or generated using the feature generation code.) 
1. data_nodefeats.txt : node features file.
	format: 
		- the header starts with @DATA on a new line, everything above it is ignored
      	- lines starting with # are treated as comments
		- data lines are the following fields which are tab separated: scene_number segment_number label feature1 feature2 .. feature<n>  
2. data_edgefeats.txt : edge features file.
	format: 
		- the header starts with @DATA on a new line, everything above it is ignored
      	- lines starting with # are treated as comments
		- data lines are the following fields which are tab separated: scene_number segment_1_number segment_2_number label_1 label_2 feature1 feature2 .. feature<n>  
3. labelmap.txt : mapping from the linenumber of labels.txt to the label number used by the classifer

Scripts :

1. initialize.sh : script to generate data files in the correct format 
2. filter.pl : removes the headers from the feature files.
3. normalize.m : normailzes the feature values
4. binfeats.m : bins the features into 10 bins
5. getBinStumps.m :  a function used by binfeats.m 
6. format.pl : reads the data_nodefeats.b.txt and data_edgefeats.b.txt files and generates the one datas_<n>.txt file per scene in the svmstruct input format.
7. clean.sh : cleaning script which removes all the files generated by initialize script and the learn/classify scripts.

NOTE: The objectMap files need not be copied into the created directory as the run.sh uses the ones in the svm-python-v204 directory, these are used by the code to define the set of labels deifining an object: home_objectMap.txt / office_objectMap.txt : the list of labels forming a object (one object per line)

Step 2 : 
run initialize.sh script inside the created directory
It generates the datas_<scene_number>.txt files in the format required by the svm code.
It also generates the fold directories : fold1, fold2, fold3, fold4 
and the following sub-directories:
 1. models folder: the final model is saved here
 2. imodels folder: intermediate models are saved here
 3. logs folder: the model training logs are saved here
 4. pred folder: the classifier logs and output are saved here


Step 3: Create the train and test files
each fold directory needs to have the train and test files:
 1. test<n> : list of test scene data files in the n-th fold (paths to the datas_<scene_number>.txt files in the test set)
 2. train<n> : list of train scene data files in the n-th fold (paths to the datas_<scene_number>.txt files in the train set)
NOTE: to change the folds the test<n> and train<n> files need to be changed.

Example file where the created directory was homedata
$ cat fold1/test1 
/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_14.txt
/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_17.txt
/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_18.txt
/opt/ros/diamondback/stacks/scene_labelling_rgbd/svm-python-v204/homedata/datas_19.txt




Step 4: Run run_parallel.sh or run_sequential.sh script inside the created directory to train the model and classify.
 


